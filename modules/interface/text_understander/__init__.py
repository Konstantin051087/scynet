# modules/interface/text_understander/__init__.py

import os
import sys
import logging
import asyncio
from typing import Dict, Any, Optional, List
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –¥–ª—è –∏–º–ø–æ—Ä—Ç–æ–≤
sys.path.append(os.path.dirname(__file__))

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logger = logging.getLogger(__name__)

# –ò–º–ø–æ—Ä—Ç –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫
try:
    from .intent_classifier import IntentClassifier
    from .entity_extractor import EntityExtractor
    from .sentiment_analyzer import SentimentAnalyzer
except ImportError as e:
    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ TextUnderstander: {e}")
    
    # –°–æ–∑–¥–∞–µ–º –∑–∞–≥–ª—É—à–∫–∏ –¥–ª—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
    class IntentClassifier:
        def __init__(self, config_path: Optional[str] = None):
            self.config_path = config_path or "config/modules/text_understander.yaml"
            self.is_initialized = False
        
        async def initialize(self):
            self.is_initialized = True
            
        async def classify(self, text: str, context: Optional[Dict] = None) -> Dict[str, Any]:
            return {"intent": "unknown", "confidence": 0.5}
        
        async def get_model_info(self) -> Dict[str, Any]:
            return {"status": "stub", "version": "1.0"}
        
        async def shutdown(self):
            self.is_initialized = False

    class EntityExtractor:
        def __init__(self, config_path: Optional[str] = None):
            self.config_path = config_path or "config/modules/text_understander.yaml"
            self.is_initialized = False
            
            # –°–æ–∑–¥–∞–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—ã–π –∫–æ–Ω—Ñ–∏–≥ –µ—Å–ª–∏ —Ñ–∞–π–ª–∞ –Ω–µ—Ç
            if not os.path.exists(self.config_path):
                self._create_default_config()
        
        def _create_default_config(self):
            """–°–æ–∑–¥–∞–µ—Ç –¥–µ—Ñ–æ–ª—Ç–Ω—ã–π –∫–æ–Ω—Ñ–∏–≥ –µ—Å–ª–∏ —Ñ–∞–π–ª –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç"""
            default_config = {
                "entity_types": ["PERSON", "LOCATION", "ORGANIZATION", "DATE"],
                "min_confidence": 0.7,
                "language": "ru"
            }
            os.makedirs(os.path.dirname(self.config_path), exist_ok=True)
            import yaml
            with open(self.config_path, 'w', encoding='utf-8') as f:
                yaml.dump(default_config, f)
        
        async def initialize(self):
            self.is_initialized = True
            
        async def extract(self, text: str, nlp_result: Optional[Dict] = None) -> List[Dict]:
            return []
        
        async def shutdown(self):
            self.is_initialized = False

    class SentimentAnalyzer:
        def __init__(self, config_path: Optional[str] = None):
            self.config_path = config_path or "config/modules/text_understander.yaml"
            self.is_initialized = False
        
        async def initialize(self):
            self.is_initialized = True
            
        async def analyze(self, text: str) -> Dict[str, Any]:
            return {"sentiment": "neutral", "score": 0.0, "confidence": 0.5}
        
        async def shutdown(self):
            self.is_initialized = False

# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –∏–∑ –≤—Ç–æ—Ä–æ–≥–æ —Ñ–∞–π–ª–∞
try:
    from .nlp_engine import NlpEngine
    from .context_integrator import ContextIntegrator
except ImportError:
    logger.warning("NlpEngine –∏–ª–∏ ContextIntegrator –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –∑–∞–≥–ª—É—à–∫–∏")
    
    class NlpEngine:
        def __init__(self, config_path: Optional[str] = None):
            self.config_path = config_path
            self.is_initialized = False
        
        async def initialize(self):
            self.is_initialized = True
            
        async def process(self, text: str) -> Dict[str, Any]:
            return {"tokens": text.split(), "language": "ru", "pos_tags": []}
        
        async def shutdown(self):
            self.is_initialized = False

    class ContextIntegrator:
        def __init__(self, config_path: Optional[str] = None):
            self.config_path = config_path
            self.is_initialized = False
            self.user_contexts = {}
        
        async def initialize(self):
            self.is_initialized = True
            
        async def get_context(self, user_id: str, external_context: Optional[Dict] = None) -> Dict[str, Any]:
            context = self.user_contexts.get(user_id, {})
            if external_context:
                context.update(external_context)
            return context
        
        async def update_context(self, user_id: str, text: str, intent: Dict, entities: List[Dict]):
            if user_id not in self.user_contexts:
                self.user_contexts[user_id] = {}
            
            self.user_contexts[user_id].update({
                "last_text": text,
                "last_intent": intent,
                "last_entities": entities,
                "timestamp": asyncio.get_event_loop().time()
            })
        
        async def shutdown(self):
            self.is_initialized = False

class TextUnderstander:
    def __init__(self, config_path: Optional[str] = None):
        self.logger = logger
        self.config_path = config_path or "config/modules/text_understander.yaml"
        self.is_initialized = False
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ —Å –≥–∞—Ä–∞–Ω—Ç–∏–µ–π –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ config_path
        self.nlp_engine = NlpEngine(self.config_path)
        self.intent_classifier = IntentClassifier(self.config_path)
        self.entity_extractor = EntityExtractor(self.config_path)  # –¢–µ–ø–µ—Ä—å config_path –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ –Ω–µ None
        self.sentiment_analyzer = SentimentAnalyzer(self.config_path)
        self.context_integrator = ContextIntegrator(self.config_path)
        
        self.logger.info("üìù TextUnderstander —Å–æ–∑–¥–∞–Ω")
    
    async def initialize(self):
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤"""
        try:
            self.logger.info("üîÑ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è TextUnderstander...")
            
            # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
            await asyncio.gather(
                self.nlp_engine.initialize(),
                self.intent_classifier.initialize(),
                self.entity_extractor.initialize(),
                self.sentiment_analyzer.initialize(),
                self.context_integrator.initialize(),
                return_exceptions=True
            )
            
            self.is_initialized = True
            self.logger.info("‚úÖ TextUnderstander –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ TextUnderstander: {e}")
            self.is_initialized = False
    
    async def process_text(self, text: str, user_id: str = "default", context: Optional[Dict] = None) -> Dict[str, Any]:
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞"""
        if not self.is_initialized:
            await self.initialize()
        
        try:
            # –ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
            context_data = await self.context_integrator.get_context(user_id, context)
            
            # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–∞–∑–Ω—ã–º–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º–∏
            nlp_result, intent_result, entities_result, sentiment_result = await asyncio.gather(
                self.nlp_engine.process(text),
                self.intent_classifier.classify(text, context_data),
                self.entity_extractor.extract(text),
                self.sentiment_analyzer.analyze(text),
                return_exceptions=True
            )
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏—Å–∫–ª—é—á–µ–Ω–∏–π
            if isinstance(nlp_result, Exception):
                self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ NLP –æ–±—Ä–∞–±–æ—Ç–∫–∏: {nlp_result}")
                nlp_result = {"tokens": text.split(), "language": "ru", "pos_tags": []}
            
            if isinstance(intent_result, Exception):
                self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –Ω–∞–º–µ—Ä–µ–Ω–∏—è: {intent_result}")
                intent_result = {"intent": "error", "confidence": 0.0}
            
            if isinstance(entities_result, Exception):
                self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Å—É—â–Ω–æ—Å—Ç–µ–π: {entities_result}")
                entities_result = []
            
            if isinstance(sentiment_result, Exception):
                self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏: {sentiment_result}")
                sentiment_result = {"sentiment": "neutral", "score": 0.0, "confidence": 0.5}
            
            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
            await self.context_integrator.update_context(user_id, text, intent_result, entities_result)
            
            return {
                "text": text,
                "user_id": user_id,
                "intent": intent_result,
                "entities": entities_result,
                "sentiment": sentiment_result,
                "nlp_result": nlp_result,
                "context": context_data,
                "success": True
            }
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞: {e}")
            return {
                "text": text,
                "user_id": user_id,
                "intent": {"intent": "error", "confidence": 0.0},
                "entities": [],
                "sentiment": {"sentiment": "neutral", "score": 0.0, "confidence": 0.5},
                "nlp_result": {"tokens": text.split(), "language": "ru", "pos_tags": []},
                "context": {},
                "success": False,
                "error": str(e)
            }
    
    async def get_status(self) -> Dict[str, Any]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç—É—Å –º–æ–¥—É–ª—è"""
        model_info = await self.intent_classifier.get_model_info()
        
        return {
            "initialized": self.is_initialized,
            "config_path": self.config_path,
            "model_info": model_info,
            "components": {
                "nlp_engine": self.nlp_engine.is_initialized,
                "intent_classifier": self.intent_classifier.is_initialized,
                "entity_extractor": self.entity_extractor.is_initialized,
                "sentiment_analyzer": self.sentiment_analyzer.is_initialized,
                "context_integrator": self.context_integrator.is_initialized
            }
        }
    
    async def shutdown(self):
        """–ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã"""
        self.logger.info("üõë –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã TextUnderstander...")
        
        await asyncio.gather(
            self.nlp_engine.shutdown(),
            self.intent_classifier.shutdown(),
            self.entity_extractor.shutdown(),
            self.sentiment_analyzer.shutdown(),
            self.context_integrator.shutdown(),
            return_exceptions=True
        )
        
        self.is_initialized = False
        self.logger.info("‚úÖ TextUnderstander –∑–∞–≤–µ—Ä—à–∏–ª —Ä–∞–±–æ—Ç—É")

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞
text_understander = TextUnderstander()